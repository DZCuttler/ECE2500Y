{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8053d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/miniforge3/envs/venv/lib/python3.10/site-packages/compressai/models/video/google.py:353: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from model_splitting import split_model\n",
    "from mnist_cnn import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from Tx_Rx import transmit, receive\n",
    "import threading\n",
    "import time\n",
    "from bottlefit_injection import stage2_training\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce621f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HECS import hecs_bottleneck, training_stage1, training_stage2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cff9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/MNIST_Bottlefit.pt', weights_only=False).to('mps')\n",
    "# nn.Sequential(*[layer for seq in model.children() for layer in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a8bfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ConvTranspose2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef5a6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6546e0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(head.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205dbf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvTranspose2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " Flatten(start_dim=1, end_dim=-1),\n",
       " Linear(in_features=6272, out_features=512, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=512, out_features=256, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=256, out_features=128, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=128, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tail.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16dd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainset, _, testset = MNIST()\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "    \n",
    "encoder = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2), \n",
    "    nn.Conv2d(64, 8, 3, padding=1),\n",
    ")\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "    nn.ConvTranspose2d(8, 32, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(32, 64, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    ")\n",
    "\n",
    "bottleneck = EntropyBottleneck(8)\n",
    "\n",
    "model = torch.load('models/MNIST_CNN_Complex.pt', weights_only=False).to('mps')\n",
    "head, tail = split_model(model, 10)\n",
    "\n",
    "student = hecs_bottleneck(encoder, bottleneck, decoder, copy.deepcopy(tail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8f1f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       " ReLU(),\n",
       " Flatten(start_dim=1, end_dim=-1),\n",
       " Linear(in_features=6272, out_features=512, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=512, out_features=256, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=256, out_features=128, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=128, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tail.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625b9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 332.3908\n",
      "Epoch 2/10, Loss: 14.8213\n",
      "Epoch 3/10, Loss: 9.1526\n",
      "Epoch 4/10, Loss: 7.7052\n",
      "Epoch 5/10, Loss: 6.8733\n",
      "Epoch 6/10, Loss: 6.6553\n",
      "Epoch 7/10, Loss: 6.3463\n",
      "Epoch 8/10, Loss: 6.2874\n",
      "Epoch 9/10, Loss: 6.2260\n",
      "Epoch 10/10, Loss: 6.1512\n"
     ]
    }
   ],
   "source": [
    "training_stage1(model, student, trainloader, epochs=10, lr=0.01, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792de639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.46%\n",
      "Latency per batch: 0.1073 seconds\n"
     ]
    }
   ],
   "source": [
    "student.eval()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
    "\n",
    "        time.sleep(0.001)  # Add delay between batches to simulate real-world conditions (also prevents crash with small batches)\n",
    "\n",
    "        torch.mps.synchronize()\n",
    "        start_time = time.time()\n",
    "        outputs = student(inputs)\n",
    "        torch.mps.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "latency =  sum(times) / len(times)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Latency per batch: {latency:.4f} seconds\")\n",
    "\n",
    "# Accuracy: 61.68%\n",
    "# Latency per batch: 0.1203 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2fbfc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9927\n",
      "Epoch 2/10, Loss: 0.5897\n",
      "Epoch 3/10, Loss: 0.4424\n",
      "Epoch 4/10, Loss: 0.3378\n",
      "Epoch 5/10, Loss: 0.2703\n",
      "Epoch 6/10, Loss: 0.2178\n",
      "Epoch 7/10, Loss: 0.1771\n",
      "Epoch 8/10, Loss: 0.1495\n",
      "Epoch 9/10, Loss: 0.1268\n",
      "Epoch 10/10, Loss: 0.1040\n"
     ]
    }
   ],
   "source": [
    "training_stage2(model, student, trainloader, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92c72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.06%\n",
      "Latency per batch: 0.1240 seconds\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
    "\n",
    "        time.sleep(0.001)  # Add delay between batches to simulate real-world conditions (also prevents crash with small batches)\n",
    "\n",
    "        torch.mps.synchronize()\n",
    "        start_time = time.time()\n",
    "        outputs = student(inputs)\n",
    "        torch.mps.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "latency =  sum(times) / len(times)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Latency per batch: {latency:.4f} seconds\")\n",
    "\n",
    "# Accuracy: 97.06%\n",
    "# Latency per batch: 0.1240 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
